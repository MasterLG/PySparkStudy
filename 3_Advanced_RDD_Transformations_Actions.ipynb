{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_x_RyUnJwZb",
        "outputId": "5b091242-5ce1-4f29-8195-7bd50b61a542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=6a1148e01970c64b6602f6aeba60b7c0d9cfd42be807b183f05e3bdda336bb1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf"
      ],
      "metadata": {
        "id": "_HQtiOcXKYbp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initializing Spark\n",
        "conf = SparkConf().setAppName(\"RDD_practice\").setMaster(\"local[*]\") \n",
        "sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "4VbT95x7Kn-H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4EWVbtXegUz",
        "outputId": "8cc0d934-41fb-4d1e-c680-47275775b928"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SparkContext master=local[*] appName=RDD_practice>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets see how many cores are available\n",
        "sc.defaultParallelism"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYVcKGs_eyHf",
        "outputId": "55e216b7-8737-4954-ba99-38f2b5a7da77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate random data\n",
        "import random\n",
        "randomlist =  random.sample(range(0, 40),10)\n",
        "print(randomlist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBBrEM_hoY1s",
        "outputId": "fc6f272c-0872-4588-e4c8-686ee733fea8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[39, 11, 21, 5, 12, 19, 25, 22, 15, 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create RDD\n",
        "#I want to split my data into 4 parts. We are going to use \"collect\" because we have small data.\n",
        "rdd1 = sc.parallelize(randomlist, 4)\n",
        "rdd1.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-mKP3TForFn",
        "outputId": "1dafd397-645c-44b0-8dbc-e9d52d8b2171"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[39, 11, 21, 5, 12, 19, 25, 22, 15, 34]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data distributions in partitions\n",
        "rdd1.getNumPartitions()\n",
        "#lets print all partitions\n",
        "print(rdd1.glom().collect())\n",
        "#lets print first 2 partitions\n",
        "print(rdd1.glom().take(2))\n",
        "#lets print last partition\n",
        "print(rdd1.glom().collect()[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQERaHGSppOr",
        "outputId": "dd330573-5492-4b72-cd00-76167e5086af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[31, 0], [1, 22], [32, 27], [7, 21, 23, 3]]\n",
            "[[31, 0], [1, 22]]\n",
            "[7, 21, 23, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#count\n",
        "print(rdd1.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkDtf1R9rLeN",
        "outputId": "e7e2e358-6194-400a-ad5b-4c26b11f813a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first\n",
        "print(rdd1.first())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4vpQ3BQrYvu",
        "outputId": "48b72433-6072-4538-a68b-bb5c6f198614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#top\n",
        "print(rdd1.top(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWJ7w5y7rjxp",
        "outputId": "f5064f4d-2e2c-4ae1-e84b-71f3af5eebeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32, 31]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#distinct\n",
        "print(rdd1.distinct().collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5YjeJa7sM5b",
        "outputId": "76aefea3-32f7-486a-957b-be1ef30f74a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 32, 1, 21, 22, 31, 27, 7, 23, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#map. map transformation returns a new rdd\n",
        "rdd_map = rdd1.map(lambda item: (item + 3) * 3 )\n",
        "print(rdd_map.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbjjSt4us3iI",
        "outputId": "6f39939a-5e87-4905-d17a-8518fa8da9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[102, 9, 12, 75, 105, 90, 30, 72, 78, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filter. filter returns a new dataset\n",
        "rdd_filter = rdd1.filter(lambda x: x%3 == 0)\n",
        "print(rdd_filter.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vgEpIlJulcP",
        "outputId": "060dd071-7fc2-434c-90f0-01316e8d2cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 27, 21, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#flatMap. flatmap is similar to map, but each item is can be mapped to 0 or more output items. It collects in to single list.\n",
        "rdd_flatmap = rdd1.flatMap(lambda x: [ x+2, x+5 ])\n",
        "print(rdd_flatmap.collect())\n",
        "#lets use reduce action. \n",
        "rdd_flatmap.reduce(lambda x, y : x+y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uwKdGe-vHQ6",
        "outputId": "6caee5c9-6fbe-49b0-bf04-cc0a6b9dd681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33, 36, 2, 5, 3, 6, 24, 27, 34, 37, 29, 32, 9, 12, 23, 26, 25, 28, 5, 8]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "404"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive statistics\n",
        "print([rdd1.max(),rdd1.min(),rdd1.mean(),round(rdd1.stdev(), 2 ),rdd1.sum()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny3WUqSA0-ge",
        "outputId": "5e87b648-2d9c-4b03-9ade-350612aac3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32, 0, 16.7, 11.99, 167]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mapPartitions. We will have a specific calculation for each partitions.\n",
        "def myfunc(partition):\n",
        "  sum = 0\n",
        "  for item in partition:\n",
        "    sum = sum + item\n",
        "  yield sum\n",
        "#We can not use return here, because it returns only one result. Here we want one result per partition.\n",
        "print(rdd1.mapPartitions(myfunc).collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp1zcfpw1cDr",
        "outputId": "c9e1db45-db4c-40f4-e802-97102e15328d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31, 23, 59, 54]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#union. it returns a new dataset. Unions the elements of dataset and the argument.\n",
        "print(rdd1.collect())\n",
        "#we create rrd2 with  2 partitions\n",
        "rdd2 = sc.parallelize([1,14,20,2028,10,13,3],2)\n",
        "print(rdd2.collect())\n",
        "\n",
        "rdd_union = rdd1.union(rdd2)\n",
        "print(rdd_union.collect())\n",
        "\n",
        "#lets check howe many partitions we have\n",
        "print(rdd_union.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maCCH52HGlt6",
        "outputId": "a98fd21b-8db2-41da-f5a1-46b9123aca62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31, 0, 1, 22, 32, 27, 7, 21, 23, 3]\n",
            "[1, 14, 20, 2028, 10, 13, 3]\n",
            "[31, 0, 1, 22, 32, 27, 7, 21, 23, 3, 1, 14, 20, 2028, 10, 13, 3]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#intersection\n",
        "rdd_intersection = rdd1.intersection(rdd2)\n",
        "print(rdd_intersection.collect())\n",
        "#how many partitions we have \n",
        "print(rdd_intersection.getNumPartitions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z9CSzBlJGSJ",
        "outputId": "f547bee2-973d-4124-f085-8eaa3e226248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find empty partitions\n",
        "print(rdd_intersection.glom().collect())\n",
        "\n",
        "counter = 0\n",
        "for item in rdd_intersection.glom().collect():\n",
        "  if len(item)==0:\n",
        "    counter = counter+1\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcsuKPM5JXz6",
        "outputId": "e0e5bcea-87a4-4a88-c723-4c2b2e7148c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[], [1], [], [3], [], []]\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#coalesce(numPartitions).we use to reduce the size of the partitions to the numPartitions.\n",
        "print(rdd_intersection.coalesce(1).glom().collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_tsYRwVK9Ju",
        "outputId": "abb39f83-da21-4fed-c7dc-a4dab28a008a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#takeSample(withReplacement, num, [seed]).It is advised to use takeSample for big data sizes.\n",
        "print(rdd1.takeSample(False, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtWpPCsVNvpi",
        "outputId": "538fc021-30ff-4391-d223-257073c817c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 1, 22, 7, 27]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#takeOrdered(n, [ordering])\n",
        "print(rdd1.takeOrdered(5))\n",
        "#for desc\n",
        "print(rdd1.takeOrdered(5, key = lambda x: -x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feyxrcZlOa9I",
        "outputId": "f11c353a-7bc3-44b7-c745-a10df0ea8e33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 11, 12, 15, 19]\n",
            "[39, 34, 25, 22, 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reduce(func).aggregate elements of the dataset using a function.\n",
        "print(rdd1.reduce(lambda x,y : x-y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiCVEStfvHlE",
        "outputId": "761eeb74-19dd-45a6-ab5a-c73ccb566791"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reduceByKey\n",
        "rdd_Rbk=sc.parallelize([(1,4),(7,10),(5,7),(1,12),(7,12),(7,1),(9,1),(7,4)],2)\n",
        "print(rdd_Rbk.glom().collect())\n",
        "\n",
        "print(rdd_Rbk.reduceByKey(lambda x,y : x+y).collect())\n",
        "\n",
        "#user-friendly visualization\n",
        "import pandas as pd\n",
        "Counter = pd.DataFrame({'Key':rdd_Rbk.keys().collect(),\n",
        "                        'Values':rdd_Rbk.values().collect()})\n",
        "print(Counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N3PAsP0vpbk",
        "outputId": "12e303cb-bf63-46f5-e31c-c952292d87f2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(1, 4), (7, 10), (5, 7), (1, 12)], [(7, 12), (7, 1), (9, 1), (7, 4)]]\n",
            "[(1, 16), (7, 27), (5, 7), (9, 1)]\n",
            "   Key  Values\n",
            "0    1       4\n",
            "1    7      10\n",
            "2    5       7\n",
            "3    1      12\n",
            "4    7      12\n",
            "5    7       1\n",
            "6    9       1\n",
            "7    7       4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sortByKey\n",
        "print(rdd_Rbk.reduceByKey(lambda x,y : x+y).sortByKey(False).collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFlmkZrEyAbP",
        "outputId": "55c58e54-ca78-4b2a-f39d-74c5000f2f31"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(9, 1), (7, 27), (5, 7), (1, 16)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#countByKey\n",
        "print(rdd_Rbk.countByKey())\n",
        "#or\n",
        "print(sorted(rdd_Rbk.countByKey().items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVcbg1Ilyabs",
        "outputId": "b7bc5331-2e59-4260-921f-a076f1703aef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'int'>, {1: 2, 7: 4, 5: 1, 9: 1})\n",
            "[(1, 2), (5, 1), (7, 4), (9, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#groupByKey. there is a difference between reduce and groupByKey. it is not good for big data.use carefully.\n",
        "rdd_group = rdd_Rbk.groupByKey()\n",
        "print(rdd_group.getNumPartitions())\n",
        "\n",
        "for item in rdd_group.collect():\n",
        "  print(item[0], [values for values in item[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO3bU1B3zBaU",
        "outputId": "acbbea6e-d4a7-45c6-d405-ad17d1b8e7c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "1 [4, 12]\n",
            "7 [10, 12, 1, 4]\n",
            "5 [7]\n",
            "9 [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lookup(key)\n",
        "rdd_Rbk.lookup(7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtKNYksu2avy",
        "outputId": "35abde19-ff04-4b62-f50c-a3d7e5aa9d05"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 12, 1, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cache\n",
        "#By default, each transformed RDD may be recomputed each time you run an action on it.\n",
        "#However, you may also persist an RDD in memory using the persist (or cache) method,\n",
        "#in which case Spark will keep the elements around on the cluster for much faster access the next time you query it.\n",
        "#it is still in memory.gc won't collect it.\n",
        "rdd_Rbk.persist()\n",
        "#persistence.We use MEMORY_AND_DISK because 1TB of data dows not fit in to 32GB RAM.\n",
        "from pyspark import StorageLevel\n",
        "rdd1.persist(StorageLevel.MEMORY_AND_DISK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ei0mbsfT2mOE",
        "outputId": "f568c458-82c2-4f96-d6a1-ffa94d8f799e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}